{
 "bad": [
  "airflow.configuration.conf",
  "airflow.configuration.conf.get",
  "airflow.exceptions.AirflowException",
  "airflow.hooks.base.BaseHook",
  "airflow.kubernetes.kube_client",
  "airflow.kubernetes.kube_client.ApiException",
  "airflow.kubernetes.kube_client.get_kube_client",
  "airflow.models.BaseOperator",
  "airflow.models.DAG",
  "airflow.providers.apache.spark.example_dags.example_spark_dag.args",
  "airflow.providers.apache.spark.hooks.spark_jdbc.SparkJDBCHook",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script._create_spark_session",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script._parse_arguments",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script._run_spark",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script.set_common_options",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script.spark_read_from_jdbc",
  "airflow.providers.apache.spark.hooks.spark_jdbc_script.spark_write_to_jdbc",
  "airflow.providers.apache.spark.hooks.spark_sql.SparkSqlHook",
  "airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook",
  "airflow.providers.apache.spark.operators.spark_jdbc.SparkJDBCOperator",
  "airflow.providers.apache.spark.operators.spark_sql.SparkSqlOperator",
  "airflow.providers.apache.spark.operators.spark_submit.SparkSubmitOperator",
  "airflow.security.kerberos.renew_from_kt",
  "airflow.settings.WEB_COLORS",
  "airflow.utils.dates.days_ago",
  "airflow.utils.decorators.apply_defaults",
  "airflow.utils.log.logging_mixin.LoggingMixin",
  "argparse.ArgumentParser",
  "os.environ.copy",
  "os.path.abspath",
  "os.path.dirname",
  "os.path.join",
  "pyspark.sql.SparkSession.builder.appName",
  "re.I",
  "re.search",
  "re.sub",
  "subprocess.PIPE",
  "subprocess.Popen",
  "subprocess.STDOUT",
  "time.sleep",
  "typing.Any",
  "typing.Dict",
  "typing.Iterator",
  "typing.List",
  "typing.Optional",
  "typing.Union"
 ],
 "deps": {
  "airflow": [],
  "argparse": [],
  "kubernetes": [
   "python-kubernetes/conda-forge/noarch/python-kubernetes-12.0.1-pyhd3deb0d_0"
  ],
  "os": [],
  "pyspark": [
   "pyspark/conda-forge/noarch/pyspark-2.4.5-py_0"
  ],
  "re": [],
  "subprocess": [],
  "time": [],
  "typing": []
 }
}