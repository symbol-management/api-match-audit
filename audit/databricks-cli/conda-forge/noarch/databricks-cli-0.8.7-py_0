{
 "bad": [
  "PythonShell.IPython.get_ipython",
  "abc.ABCMeta",
  "abc.abstractmethod",
  "base64.b64decode",
  "base64.b64encode",
  "base64.standard_b64encode",
  "click.Choice",
  "click.INT",
  "click.MissingParameter",
  "click.Option",
  "click.ParamType",
  "click.Path",
  "click.UsageError",
  "click.argument",
  "click.command",
  "click.echo",
  "click.edit",
  "click.get_current_context",
  "click.group",
  "click.option",
  "click.prompt",
  "click.style",
  "configparser.ConfigParser",
  "copy.deepcopy",
  "databricksCli.init_databricks_cli_config_provider",
  "databricks_cli.cli.cli",
  "databricks_cli.click_types.ClusterIdClickType",
  "databricks_cli.click_types.ClusterIdClickType.help",
  "databricks_cli.click_types.ContextObject",
  "databricks_cli.click_types.JobIdClickType",
  "databricks_cli.click_types.JobIdClickType.help",
  "databricks_cli.click_types.JsonClickType",
  "databricks_cli.click_types.JsonClickType.help",
  "databricks_cli.click_types.OneOfOption",
  "databricks_cli.click_types.OutputClickType",
  "databricks_cli.click_types.OutputClickType.help",
  "databricks_cli.click_types.OutputClickType.is_json",
  "databricks_cli.click_types.RunIdClickType",
  "databricks_cli.click_types.SecretKeyClickType",
  "databricks_cli.click_types.SecretKeyClickType.help",
  "databricks_cli.click_types.SecretPrincipalClickType",
  "databricks_cli.click_types.SecretPrincipalClickType.help",
  "databricks_cli.click_types.SecretScopeClickType",
  "databricks_cli.click_types.SecretScopeClickType.help",
  "databricks_cli.clusters.api.ClusterApi",
  "databricks_cli.clusters.cli._clusters_to_table",
  "databricks_cli.clusters.cli.clusters_group",
  "databricks_cli.clusters.cli.create_cli",
  "databricks_cli.clusters.cli.delete_cli",
  "databricks_cli.clusters.cli.edit_cli",
  "databricks_cli.clusters.cli.get_cli",
  "databricks_cli.clusters.cli.list_cli",
  "databricks_cli.clusters.cli.list_node_types_cli",
  "databricks_cli.clusters.cli.list_zones_cli",
  "databricks_cli.clusters.cli.permanent_delete_cli",
  "databricks_cli.clusters.cli.resize_cli",
  "databricks_cli.clusters.cli.restart_cli",
  "databricks_cli.clusters.cli.spark_versions_cli",
  "databricks_cli.clusters.cli.start_cli",
  "databricks_cli.configure.cli.PROMPT_HOST",
  "databricks_cli.configure.cli.PROMPT_PASSWORD",
  "databricks_cli.configure.cli.PROMPT_TOKEN",
  "databricks_cli.configure.cli.PROMPT_USERNAME",
  "databricks_cli.configure.cli._DbfsHost",
  "databricks_cli.configure.cli._configure_cli_password",
  "databricks_cli.configure.cli._configure_cli_token",
  "databricks_cli.configure.cli.configure_cli",
  "databricks_cli.configure.config._get_api_client",
  "databricks_cli.configure.config.debug_option",
  "databricks_cli.configure.config.get_profile_from_context",
  "databricks_cli.configure.config.profile_option",
  "databricks_cli.configure.config.provide_api_client",
  "databricks_cli.configure.provider.CONFIG_FILE_ENV_VAR",
  "databricks_cli.configure.provider.DEFAULT_SECTION",
  "databricks_cli.configure.provider.DatabricksConfig",
  "databricks_cli.configure.provider.DatabricksConfig.empty",
  "databricks_cli.configure.provider.DatabricksConfig.from_password",
  "databricks_cli.configure.provider.DatabricksConfig.from_token",
  "databricks_cli.configure.provider.DatabricksConfigProvider",
  "databricks_cli.configure.provider.DefaultConfigProvider",
  "databricks_cli.configure.provider.EnvironmentVariableConfigProvider",
  "databricks_cli.configure.provider.HOST",
  "databricks_cli.configure.provider.INSECURE",
  "databricks_cli.configure.provider.PASSWORD",
  "databricks_cli.configure.provider.ProfileConfigProvider",
  "databricks_cli.configure.provider.SparkTaskContextConfigProvider",
  "databricks_cli.configure.provider.TOKEN",
  "databricks_cli.configure.provider.USERNAME",
  "databricks_cli.configure.provider._config_provider",
  "databricks_cli.configure.provider._create_section_if_absent",
  "databricks_cli.configure.provider._fetch_from_fs",
  "databricks_cli.configure.provider._get_option_if_exists",
  "databricks_cli.configure.provider._get_path",
  "databricks_cli.configure.provider._home",
  "databricks_cli.configure.provider._overwrite_config",
  "databricks_cli.configure.provider._set_option",
  "databricks_cli.configure.provider.get_config",
  "databricks_cli.configure.provider.update_and_persist_config",
  "databricks_cli.dbfs.api.BUFFER_SIZE_BYTES",
  "databricks_cli.dbfs.api.DbfsApi",
  "databricks_cli.dbfs.api.DbfsErrorCodes",
  "databricks_cli.dbfs.api.FileInfo",
  "databricks_cli.dbfs.cli.cp_cli",
  "databricks_cli.dbfs.cli.dbfs_group",
  "databricks_cli.dbfs.cli.ls_cli",
  "databricks_cli.dbfs.cli.mkdirs_cli",
  "databricks_cli.dbfs.cli.mv_cli",
  "databricks_cli.dbfs.cli.rm_cli",
  "databricks_cli.dbfs.dbfs_path.DbfsPath",
  "databricks_cli.dbfs.dbfs_path.DbfsPath.from_api_path",
  "databricks_cli.dbfs.dbfs_path.DbfsPath.is_valid",
  "databricks_cli.dbfs.dbfs_path.DbfsPathClickType",
  "databricks_cli.dbfs.exceptions.LocalFileExistsException",
  "databricks_cli.groups.api.GroupsApi",
  "databricks_cli.groups.cli.MEMBER_OPTIONS",
  "databricks_cli.groups.cli.add_member_cli",
  "databricks_cli.groups.cli.create_cli",
  "databricks_cli.groups.cli.delete_cli",
  "databricks_cli.groups.cli.groups_group",
  "databricks_cli.groups.cli.list_all_cli",
  "databricks_cli.groups.cli.list_members_cli",
  "databricks_cli.groups.cli.list_parents_cli",
  "databricks_cli.groups.cli.remove_member_cli",
  "databricks_cli.initialize_cli_for_databricks_notebooks",
  "databricks_cli.jobs.api.JobsApi",
  "databricks_cli.jobs.cli._jobs_to_table",
  "databricks_cli.jobs.cli.create_cli",
  "databricks_cli.jobs.cli.delete_cli",
  "databricks_cli.jobs.cli.get_cli",
  "databricks_cli.jobs.cli.jobs_group",
  "databricks_cli.jobs.cli.list_cli",
  "databricks_cli.jobs.cli.reset_cli",
  "databricks_cli.jobs.cli.run_now_cli",
  "databricks_cli.libraries.api.LibrariesApi",
  "databricks_cli.libraries.cli.CRAN_PACKAGE_HELP",
  "databricks_cli.libraries.cli.CRAN_REPO_HELP",
  "databricks_cli.libraries.cli.EGG_HELP",
  "databricks_cli.libraries.cli.INSTALL_OPTIONS",
  "databricks_cli.libraries.cli.JAR_HELP",
  "databricks_cli.libraries.cli.MAVEN_COORDINATES_HELP",
  "databricks_cli.libraries.cli.MAVEN_EXCLUSION_HELP",
  "databricks_cli.libraries.cli.MAVEN_REPO_HELP",
  "databricks_cli.libraries.cli.PYPI_PACKAGE_HELP",
  "databricks_cli.libraries.cli.PYPI_REPO_HELP",
  "databricks_cli.libraries.cli.UNINSTALL_OPTIONS",
  "databricks_cli.libraries.cli.WHEEL_HELP",
  "databricks_cli.libraries.cli._all_cluster_statuses",
  "databricks_cli.libraries.cli._cluster_status",
  "databricks_cli.libraries.cli._get_library_from_options",
  "databricks_cli.libraries.cli._uninstall_cli_exit_help",
  "databricks_cli.libraries.cli.all_cluster_statuses_cli",
  "databricks_cli.libraries.cli.cluster_status_cli",
  "databricks_cli.libraries.cli.install_cli",
  "databricks_cli.libraries.cli.libraries_group",
  "databricks_cli.libraries.cli.list_cli",
  "databricks_cli.libraries.cli.uninstall_cli",
  "databricks_cli.runs.api.RunsApi",
  "databricks_cli.runs.cli._runs_to_table",
  "databricks_cli.runs.cli.cancel_cli",
  "databricks_cli.runs.cli.get_cli",
  "databricks_cli.runs.cli.list_cli",
  "databricks_cli.runs.cli.runs_group",
  "databricks_cli.runs.cli.submit_cli",
  "databricks_cli.sdk.ApiClient",
  "databricks_cli.sdk.ClusterService",
  "databricks_cli.sdk.DbfsService",
  "databricks_cli.sdk.GroupsService",
  "databricks_cli.sdk.JobsService",
  "databricks_cli.sdk.ManagedLibraryService",
  "databricks_cli.sdk.SecretService",
  "databricks_cli.sdk.WorkspaceService",
  "databricks_cli.sdk.api_client.TlsV1HttpAdapter",
  "databricks_cli.sdk.api_client._translate_boolean_to_query_param",
  "databricks_cli.secrets.api.SecretApi",
  "databricks_cli.secrets.cli.ACL_HEADER",
  "databricks_cli.secrets.cli.DASH_MARKER",
  "databricks_cli.secrets.cli.SCOPE_HEADER",
  "databricks_cli.secrets.cli.SECRET_HEADER",
  "databricks_cli.secrets.cli._acls_to_table",
  "databricks_cli.secrets.cli._scopes_to_table",
  "databricks_cli.secrets.cli._secrets_to_table",
  "databricks_cli.secrets.cli._verify_and_translate_options",
  "databricks_cli.secrets.cli.create_scope",
  "databricks_cli.secrets.cli.delete_acl",
  "databricks_cli.secrets.cli.delete_scope",
  "databricks_cli.secrets.cli.delete_secret",
  "databricks_cli.secrets.cli.get_acl",
  "databricks_cli.secrets.cli.list_acls",
  "databricks_cli.secrets.cli.list_scopes",
  "databricks_cli.secrets.cli.list_secrets",
  "databricks_cli.secrets.cli.put_acl",
  "databricks_cli.secrets.cli.put_secret",
  "databricks_cli.secrets.cli.secrets_group",
  "databricks_cli.stack.api.CLI_VERSION_KEY",
  "databricks_cli.stack.api.DBFS_RESOURCE_IS_DIR",
  "databricks_cli.stack.api.DBFS_RESOURCE_PATH",
  "databricks_cli.stack.api.DBFS_RESOURCE_SOURCE_PATH",
  "databricks_cli.stack.api.DBFS_SERVICE",
  "databricks_cli.stack.api.JOBS_RESOURCE_JOB_ID",
  "databricks_cli.stack.api.JOBS_RESOURCE_NAME",
  "databricks_cli.stack.api.JOBS_SERVICE",
  "databricks_cli.stack.api.MS_SEC",
  "databricks_cli.stack.api.RESOURCE_DATABRICKS_ID",
  "databricks_cli.stack.api.RESOURCE_ID",
  "databricks_cli.stack.api.RESOURCE_PROPERTIES",
  "databricks_cli.stack.api.RESOURCE_SERVICE",
  "databricks_cli.stack.api.STACK_DEPLOYED",
  "databricks_cli.stack.api.STACK_NAME",
  "databricks_cli.stack.api.STACK_RESOURCES",
  "databricks_cli.stack.api.StackApi",
  "databricks_cli.stack.api.WORKSPACE_RESOURCE_OBJECT_TYPE",
  "databricks_cli.stack.api.WORKSPACE_RESOURCE_PATH",
  "databricks_cli.stack.api.WORKSPACE_RESOURCE_SOURCE_PATH",
  "databricks_cli.stack.api.WORKSPACE_SERVICE",
  "databricks_cli.stack.cli._generate_stack_status_path",
  "databricks_cli.stack.cli._load_json",
  "databricks_cli.stack.cli._save_json",
  "databricks_cli.stack.cli.deploy",
  "databricks_cli.stack.cli.download",
  "databricks_cli.stack.cli.stack_group",
  "databricks_cli.stack.exceptions.StackError",
  "databricks_cli.utils.CONTEXT_SETTINGS",
  "databricks_cli.utils.DEBUG_MODE",
  "databricks_cli.utils.InvalidConfigurationError",
  "databricks_cli.utils.InvalidConfigurationError.for_profile",
  "databricks_cli.utils.eat_exceptions",
  "databricks_cli.utils.error_and_quit",
  "databricks_cli.utils.json_cli_base",
  "databricks_cli.utils.pretty_format",
  "databricks_cli.utils.truncate_string",
  "databricks_cli.version.print_version_callback",
  "databricks_cli.version.version",
  "databricks_cli.version.version.API_VERSION",
  "databricks_cli.workspace.api.DIRECTORY",
  "databricks_cli.workspace.api.LIBRARY",
  "databricks_cli.workspace.api.NOTEBOOK",
  "databricks_cli.workspace.api.WorkspaceApi",
  "databricks_cli.workspace.api.WorkspaceFileInfo",
  "databricks_cli.workspace.cli.delete_cli",
  "databricks_cli.workspace.cli.export_dir_cli",
  "databricks_cli.workspace.cli.export_workspace_cli",
  "databricks_cli.workspace.cli.import_dir_cli",
  "databricks_cli.workspace.cli.import_workspace_cli",
  "databricks_cli.workspace.cli.ls_cli",
  "databricks_cli.workspace.cli.mkdirs_cli",
  "databricks_cli.workspace.cli.workspace_group",
  "databricks_cli.workspace.types.FormatClickType",
  "databricks_cli.workspace.types.LanguageClickType",
  "databricks_cli.workspace.types.WorkspaceFormat",
  "databricks_cli.workspace.types.WorkspaceFormat.SOURCE",
  "databricks_cli.workspace.types.WorkspaceLanguage",
  "databricks_cli.workspace.types.WorkspaceLanguage.ALL",
  "databricks_cli.workspace.types.WorkspaceLanguage.EXTENSIONS",
  "databricks_cli.workspace.types.WorkspaceLanguage.get_extension",
  "databricks_cli.workspace.types.WorkspaceLanguage.to_extension",
  "databricks_cli.workspace.types.WorkspaceLanguage.to_language_and_format",
  "datetime.datetime.fromtimestamp",
  "function",
  "function.__doc__",
  "integration.dbfs.test_integration.DBFS_TEST_PATH",
  "integration.dbfs.test_integration.LOCAL_TEMP_DIR",
  "integration.dbfs.test_integration.LOCAL_TEMP_FILE",
  "integration.dbfs.test_integration.LOCAL_TEST_DIR",
  "integration.dbfs.test_integration.LOCAL_TEST_FILE",
  "integration.dbfs.test_integration.LOCAL_TEST_FILE_IN_DIR",
  "integration.dbfs.test_integration.TEST_FILE_CONTENTS",
  "integration.dbfs.test_integration.assert_dbfs_file_exists",
  "integration.dbfs.test_integration.assert_local_file_content",
  "integration.dbfs.test_integration.local_dir",
  "integration.workspace.test_integration.LOCAL_TEMP_DIR",
  "integration.workspace.test_integration.LOCAL_TEMP_FILE",
  "integration.workspace.test_integration.LOCAL_TEST_DIR",
  "integration.workspace.test_integration.PYTHON_CONTENTS",
  "integration.workspace.test_integration.PYTHON_FILE",
  "integration.workspace.test_integration.R_CONTENTS",
  "integration.workspace.test_integration.R_FILE",
  "integration.workspace.test_integration.SCALA_CONTENTS",
  "integration.workspace.test_integration.SCALA_FILE",
  "integration.workspace.test_integration.SQL_CONTENTS",
  "integration.workspace.test_integration.SQL_FILE",
  "integration.workspace.test_integration.WORKSPACE_TEST_PATH",
  "integration.workspace.test_integration.assert_local_file_contains",
  "integration.workspace.test_integration.assert_workspace_file_exists",
  "integration.workspace.test_integration.local_dir",
  "integration.workspace.test_integration.strip_suffix",
  "json.dump",
  "json.dumps",
  "json.load",
  "json.loads",
  "os.chdir",
  "os.chmod",
  "os.environ.get",
  "os.getcwd",
  "os.listdir",
  "os.makedirs",
  "os.mkdir",
  "os.path.abspath",
  "os.path.basename",
  "os.path.dirname",
  "os.path.exists",
  "os.path.expanduser",
  "os.path.isdir",
  "os.path.isfile",
  "os.path.join",
  "os.path.relpath",
  "os.path.split",
  "os.path.splitext",
  "pprint.pformat",
  "pyspark.SparkContext._active_spark_context.setLocalProperty",
  "pyspark.TaskContext.get",
  "pytest.fixture",
  "pytest.mark.usefixtures",
  "random.random",
  "requests.Session",
  "requests.adapters.HTTPAdapter",
  "requests.exceptions.HTTPError",
  "shutil.rmtree",
  "six.moves.urllib.parse.urlparse",
  "six.wraps",
  "ssl.PROTOCOL_TLSv1_2",
  "sys.argv",
  "sys.exit",
  "tabulate.tabulate",
  "tempfile.mkdtemp",
  "tests.utils.invoke_cli_runner",
  "traceback.print_exc",
  "urllib3.exceptions.InsecureRequestWarning",
  "urllib3.poolmanager.PoolManager",
  "uuid.uuid1",
  "warnings.catch_warnings",
  "warnings.simplefilter"
 ],
 "deps": {
  "PythonShell": [],
  "abc": [],
  "base64": [],
  "click": [],
  "configparser": [],
  "copy": [],
  "databricksCli": [],
  "databricks_cli": [],
  "datetime": [],
  "function": [],
  "integration": [],
  "json": [],
  "os": [],
  "pprint": [],
  "pyspark": [],
  "pytest": [],
  "random": [],
  "requests": [],
  "shutil": [],
  "six": [],
  "ssl": [],
  "sys": [],
  "tabulate": [],
  "tempfile": [],
  "tests": [],
  "traceback": [],
  "urllib3": [],
  "uuid": [],
  "warnings": []
 }
}