{
 "bad": [
  "__future__.absolute_import",
  "_set_python_path",
  "logging",
  "logging.getLogger",
  "os",
  "os.environ",
  "os.getcwd",
  "os.getenv",
  "os.kill",
  "os.makedirs",
  "os.path.exists",
  "os.path.join",
  "pkg_resources",
  "pkg_resources.resource_filename",
  "psutil",
  "psutil.process_iter",
  "retrying.retry",
  "sagemaker_inference.content_types",
  "sagemaker_inference.content_types.CSV",
  "sagemaker_inference.content_types.JSON",
  "sagemaker_inference.content_types.NPY",
  "sagemaker_inference.content_types.UTF8_TYPES",
  "sagemaker_inference.decoder",
  "sagemaker_inference.decoder.decode",
  "sagemaker_inference.default_handler_service",
  "sagemaker_inference.default_handler_service.DefaultHandlerService",
  "sagemaker_inference.default_handler_service.__name__",
  "sagemaker_inference.default_inference_handler",
  "sagemaker_inference.default_inference_handler.DefaultInferenceHandler",
  "sagemaker_inference.encoder",
  "sagemaker_inference.encoder.encode",
  "sagemaker_inference.environment",
  "sagemaker_inference.environment.Environment",
  "sagemaker_inference.environment.code_dir",
  "sagemaker_inference.environment.model_dir",
  "sagemaker_inference.transformer.Transformer",
  "sagemaker_inference.utils",
  "sagemaker_inference.utils.read_file",
  "sagemaker_inference.utils.write_file",
  "sagemaker_pytorch_serving_container.__name__",
  "sagemaker_pytorch_serving_container.handler_service.__file__",
  "signal",
  "signal.SIGTERM",
  "signal.signal",
  "subprocess",
  "subprocess.CalledProcessError",
  "subprocess.Popen",
  "subprocess.check_call",
  "sys",
  "sys.executable",
  "sys.path.append",
  "textwrap",
  "textwrap.dedent",
  "torch",
  "torch.FloatTensor",
  "torch.Tensor",
  "torch.cuda.is_available",
  "torch.device",
  "torch.from_numpy",
  "torch.jit.load",
  "torch.jit.optimized_execution",
  "torch.no_grad"
 ],
 "deps": {
  "__future__": [],
  "_set_python_path": [],
  "logging": [],
  "os": [],
  "pkg_resources": [],
  "psutil": [],
  "retrying": [],
  "sagemaker_inference": [],
  "sagemaker_pytorch_serving_container": [],
  "signal": [],
  "subprocess": [],
  "sys": [],
  "textwrap": [],
  "torch": []
 }
}