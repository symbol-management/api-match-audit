{
 "bad": [
  "BatchHardTripletLoss.BatchHardTripletLoss",
  "BatchHardTripletLoss.BatchHardTripletLoss.get_anchor_negative_triplet_mask",
  "BatchHardTripletLoss.BatchHardTripletLoss.get_anchor_positive_triplet_mask",
  "BatchHardTripletLoss.BatchHardTripletLoss.get_triplet_mask",
  "BatchHardTripletLoss.BatchHardTripletLossDistanceFunction.eucledian_distance",
  "ContrastiveLoss.SiameseDistanceMetric.COSINE_DISTANCE",
  "SentenceTransformer.SentenceTransformer",
  "SentenceTransformer._get_scheduler",
  "SimilarityFunction.COSINE",
  "SimilarityFunction.DOT_PRODUCT",
  "SimilarityFunction.EUCLIDEAN",
  "SimilarityFunction.MANHATTAN",
  "WordTokenizer.ENGLISH_STOP_WORDS",
  "WordTokenizer.WordTokenizer",
  "abc.ABC",
  "abc.abstractmethod",
  "add_notice_log_level",
  "collections.OrderedDict",
  "collections.defaultdict",
  "coloredlogs.DEFAULT_FIELD_STYLES.copy",
  "coloredlogs.DEFAULT_LEVEL_STYLES.copy",
  "coloredlogs.install",
  "conv",
  "csv.QUOTE_NONE",
  "csv.reader",
  "csv.writer",
  "enum.Enum",
  "evaluation.BinaryClassificationEvaluator.find_best_acc_and_threshold",
  "evaluation.BinaryClassificationEvaluator.find_best_f1_and_threshold",
  "evaluation.SentenceEvaluator",
  "evaluator",
  "gzip.open",
  "importlib.import_module",
  "json.dump",
  "json.load",
  "logging.DEBUG",
  "logging.Handler",
  "logging.INFO",
  "logging.Logger.notice",
  "logging.NOTSET",
  "logging.WARNING",
  "logging.addLevelName",
  "logging.getLogger",
  "loss_fct",
  "loss_model",
  "loss_model.parameters",
  "loss_model.train",
  "loss_model.zero_grad",
  "math.ceil",
  "model",
  "model.save",
  "models.Pooling",
  "models.Transformer",
  "nltk.word_tokenize",
  "numpy.arange",
  "numpy.argmax",
  "numpy.argpartition",
  "numpy.argsort",
  "numpy.array",
  "numpy.asarray",
  "numpy.concatenate",
  "numpy.dot",
  "numpy.float32",
  "numpy.generic",
  "numpy.log2",
  "numpy.max",
  "numpy.mean",
  "numpy.min",
  "numpy.nan_to_num",
  "numpy.ndarray",
  "numpy.random.choice",
  "numpy.random.shuffle",
  "numpy.sum",
  "numpy.zeros",
  "os.getenv",
  "os.listdir",
  "os.makedirs",
  "os.path.basename",
  "os.path.dirname",
  "os.path.exists",
  "os.path.expanduser",
  "os.path.isdir",
  "os.path.isfile",
  "os.path.join",
  "os.remove",
  "os.rename",
  "queue.Empty",
  "queue.PriorityQueue",
  "random.shuffle",
  "readers.InputExample",
  "readers.InputExample.InputExample",
  "requests.exceptions.HTTPError",
  "requests.get",
  "scipy.stats.pearsonr",
  "scipy.stats.spearmanr",
  "sent_embedding_dim_method",
  "sentence_transformers.SentenceTransformer",
  "sentence_transformers.SentenceTransformer.SentenceTransformer",
  "sentence_transformers.SentenceTransformer.__DOWNLOAD_SERVER__",
  "sentence_transformers.SentenceTransformer.__version__",
  "sentence_transformers.SentenceTransformer.logger",
  "sentence_transformers.cross_encoder.CrossEncoder.logger",
  "sentence_transformers.cross_encoder.evaluation.CEBinaryAccuracyEvaluator.InputExample",
  "sentence_transformers.cross_encoder.evaluation.CEBinaryAccuracyEvaluator.logger",
  "sentence_transformers.cross_encoder.evaluation.CEBinaryClassificationEvaluator.InputExample",
  "sentence_transformers.cross_encoder.evaluation.CEBinaryClassificationEvaluator.logger",
  "sentence_transformers.cross_encoder.evaluation.CECorrelationEvaluator.InputExample",
  "sentence_transformers.cross_encoder.evaluation.CECorrelationEvaluator.logger",
  "sentence_transformers.cross_encoder.evaluation.CERerankingEvaluator.logger",
  "sentence_transformers.cross_encoder.evaluation.CESoftmaxAccuracyEvaluator.InputExample",
  "sentence_transformers.cross_encoder.evaluation.CESoftmaxAccuracyEvaluator.logger",
  "sentence_transformers.datasets.ParallelSentencesDataset.SentenceTransformer",
  "sentence_transformers.datasets.ParallelSentencesDataset.logger",
  "sentence_transformers.datasets.SentenceLabelDataset.logger",
  "sentence_transformers.datasets.SentencesDataset.SentenceTransformer",
  "sentence_transformers.evaluation.BinaryClassificationEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.BinaryClassificationEvaluator.logger",
  "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.SimilarityFunction",
  "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.logger",
  "sentence_transformers.evaluation.InformationRetrievalEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.InformationRetrievalEvaluator.logger",
  "sentence_transformers.evaluation.LabelAccuracyEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.LabelAccuracyEvaluator.logger",
  "sentence_transformers.evaluation.MSEEvaluator.logger",
  "sentence_transformers.evaluation.MSEEvaluatorFromDataFrame.logger",
  "sentence_transformers.evaluation.ParaphraseMiningEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.ParaphraseMiningEvaluator.logger",
  "sentence_transformers.evaluation.SentenceEvaluator",
  "sentence_transformers.evaluation.SequentialEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.TranslationEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.TranslationEvaluator.logger",
  "sentence_transformers.evaluation.TripletEvaluator.SentenceEvaluator",
  "sentence_transformers.evaluation.TripletEvaluator.SimilarityFunction",
  "sentence_transformers.evaluation.TripletEvaluator.logger",
  "sentence_transformers.losses.BatchAllTripletLoss.BatchAllTripletLoss",
  "sentence_transformers.losses.BatchHardSoftMarginTripletLoss.BatchHardSoftMarginTripletLoss",
  "sentence_transformers.losses.BatchHardTripletLoss.BatchHardTripletLoss",
  "sentence_transformers.losses.BatchHardTripletLoss.BatchHardTripletLossDistanceFunction",
  "sentence_transformers.losses.BatchSemiHardTripletLoss.BatchSemiHardTripletLoss",
  "sentence_transformers.losses.ContrastiveLoss.ContrastiveLoss",
  "sentence_transformers.losses.ContrastiveLoss.SiameseDistanceMetric",
  "sentence_transformers.losses.CosineSimilarityLoss.CosineSimilarityLoss",
  "sentence_transformers.losses.MSELoss.MSELoss",
  "sentence_transformers.losses.MegaBatchMarginLoss.MegaBatchMarginLoss",
  "sentence_transformers.losses.MultipleNegativesRankingLoss.MultipleNegativesRankingLoss",
  "sentence_transformers.losses.OnlineContrastiveLoss.OnlineContrastiveLoss",
  "sentence_transformers.losses.SoftmaxLoss.SoftmaxLoss",
  "sentence_transformers.losses.SoftmaxLoss.logger",
  "sentence_transformers.losses.TripletLoss.TripletDistanceMetric",
  "sentence_transformers.losses.TripletLoss.TripletLoss",
  "sentence_transformers.models.ALBERT.Transformer",
  "sentence_transformers.models.Asym.Asym",
  "sentence_transformers.models.BERT.Transformer",
  "sentence_transformers.models.BoW.BoW",
  "sentence_transformers.models.BoW.logger",
  "sentence_transformers.models.CNN.CNN",
  "sentence_transformers.models.CamemBERT.Transformer",
  "sentence_transformers.models.Dense.Dense",
  "sentence_transformers.models.DistilBERT.Transformer",
  "sentence_transformers.models.LSTM.LSTM",
  "sentence_transformers.models.Normalize.Normalize",
  "sentence_transformers.models.Pooling.Pooling",
  "sentence_transformers.models.RoBERTa.Transformer",
  "sentence_transformers.models.T5.T5",
  "sentence_transformers.models.T5.logger",
  "sentence_transformers.models.Transformer.Transformer",
  "sentence_transformers.models.WKPooling.WKPooling",
  "sentence_transformers.models.WeightedLayerPooling.WeightedLayerPooling",
  "sentence_transformers.models.WordEmbeddings.WordEmbeddings",
  "sentence_transformers.models.WordEmbeddings.logger",
  "sentence_transformers.models.WordWeights.WordWeights",
  "sentence_transformers.models.WordWeights.logger",
  "sentence_transformers.models.XLMRoBERTa.Transformer",
  "sentence_transformers.models.XLNet.Transformer",
  "sentence_transformers.models.tokenizer.PhraseTokenizer.PhraseTokenizer",
  "sentence_transformers.models.tokenizer.PhraseTokenizer.logger",
  "sentence_transformers.models.tokenizer.WhitespaceTokenizer.WhitespaceTokenizer",
  "sentence_transformers.readers.LabelSentenceReader.InputExample",
  "sentence_transformers.readers.NLIDataReader.InputExample",
  "sentence_transformers.readers.PairedFilesReader.InputExample",
  "sentence_transformers.readers.STSDataReader.InputExample",
  "sentence_transformers.readers.STSDataReader.STSDataReader",
  "sentence_transformers.readers.TripletReader.InputExample",
  "sentence_transformers.util.paraphrase_mining",
  "sentence_transformers.util.pytorch_cos_sim",
  "sentence_transformers.util.semantic_search",
  "shutil.rmtree",
  "sklearn.metrics.average_precision_score",
  "sklearn.metrics.pairwise.paired_cosine_distances",
  "sklearn.metrics.pairwise.paired_euclidean_distances",
  "sklearn.metrics.pairwise.paired_manhattan_distances",
  "str.__class__.__module__",
  "string.punctuation",
  "sys.stderr",
  "tokenizer.WhitespaceTokenizer",
  "tokenizer.WordTokenizer",
  "torch.FloatTensor",
  "torch.Tensor",
  "torch.abs",
  "torch.argmax",
  "torch.cat",
  "torch.clamp",
  "torch.cosine_similarity",
  "torch.cuda.amp.GradScaler",
  "torch.cuda.amp.autocast",
  "torch.cuda.device_count",
  "torch.cuda.is_available",
  "torch.device",
  "torch.diag",
  "torch.diagonal",
  "torch.exp",
  "torch.eye",
  "torch.float",
  "torch.from_numpy",
  "torch.hub._get_torch_home",
  "torch.is_tensor",
  "torch.load",
  "torch.log1p",
  "torch.long",
  "torch.matmul",
  "torch.max",
  "torch.mean",
  "torch.mm",
  "torch.multiprocessing.get_context",
  "torch.mv",
  "torch.nn.BCEWithLogitsLoss",
  "torch.nn.Conv1d",
  "torch.nn.CrossEntropyLoss",
  "torch.nn.Embedding",
  "torch.nn.Identity",
  "torch.nn.LSTM",
  "torch.nn.Linear",
  "torch.nn.MSELoss",
  "torch.nn.Module",
  "torch.nn.Module.__init__",
  "torch.nn.ModuleList",
  "torch.nn.Parameter",
  "torch.nn.Sequential",
  "torch.nn.Sigmoid",
  "torch.nn.Tanh",
  "torch.nn.functional.cosine_similarity",
  "torch.nn.functional.normalize",
  "torch.nn.functional.pairwise_distance",
  "torch.nn.functional.relu",
  "torch.nn.functional.softmax",
  "torch.nn.utils.clip_grad_norm_",
  "torch.nn.utils.rnn.pack_padded_sequence",
  "torch.nn.utils.rnn.pad_packed_sequence",
  "torch.no_grad",
  "torch.norm",
  "torch.numel",
  "torch.optim.Optimizer",
  "torch.qr",
  "torch.reshape",
  "torch.save",
  "torch.sqrt",
  "torch.stack",
  "torch.sum",
  "torch.tensor",
  "torch.topk",
  "torch.utils.data.DataLoader",
  "torch.utils.data.Dataset",
  "torch.utils.data.IterableDataset",
  "torch.var",
  "torch.where",
  "torch.zeros",
  "tqdm.autonotebook.tqdm",
  "tqdm.autonotebook.trange",
  "tqdm.tqdm",
  "tqdm.tqdm.write",
  "transformers.AdamW",
  "transformers.AutoConfig.from_pretrained",
  "transformers.AutoModel.from_pretrained",
  "transformers.AutoModelForSequenceClassification.from_pretrained",
  "transformers.AutoTokenizer.from_pretrained",
  "transformers.T5Model.from_pretrained",
  "transformers.T5Tokenizer.from_pretrained",
  "transformers.get_constant_schedule",
  "transformers.get_constant_schedule_with_warmup",
  "transformers.get_cosine_schedule_with_warmup",
  "transformers.get_cosine_with_hard_restarts_schedule_with_warmup",
  "transformers.get_linear_schedule_with_warmup",
  "typing.Callable",
  "typing.Dict",
  "typing.Iterable",
  "typing.List",
  "typing.Optional",
  "typing.Set",
  "typing.Tuple",
  "typing.Type",
  "typing.Union",
  "util.batch_to_device",
  "util.fullname",
  "util.http_get",
  "util.import_from_string",
  "util.pytorch_cos_sim",
  "zip.extractall",
  "zipfile.ZipFile"
 ],
 "deps": {
  "BatchHardTripletLoss": [],
  "ContrastiveLoss": [],
  "SentenceTransformer": [],
  "SimilarityFunction": [],
  "WordTokenizer": [],
  "abc": [],
  "add_notice_log_level": [],
  "collections": [],
  "coloredlogs": [],
  "conv": [],
  "csv": [],
  "enum": [],
  "evaluation": [],
  "evaluator": [],
  "gzip": [],
  "importlib": [],
  "json": [],
  "logging": [],
  "loss_fct": [],
  "loss_model": [],
  "math": [],
  "model": [],
  "models": [],
  "nltk": [],
  "numpy": [],
  "os": [],
  "queue": [],
  "random": [],
  "readers": [],
  "requests": [],
  "scipy": [],
  "sent_embedding_dim_method": [],
  "sentence_transformers": [],
  "shutil": [],
  "sklearn": [],
  "str": [],
  "string": [],
  "sys": [],
  "tokenizer": [],
  "torch": [],
  "tqdm": [],
  "transformers": [],
  "typing": [],
  "util": [],
  "zip": [],
  "zipfile": []
 }
}