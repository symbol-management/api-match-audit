{
 "bad": [
  "SimpleVoter",
  "abc.ABC",
  "abc.abstractmethod",
  "call_fn",
  "checkpointer.Checkpointer",
  "collections.Counter",
  "collections.Hashable",
  "collections.OrderedDict",
  "collections.defaultdict",
  "combiner_module",
  "core.BaseLFApplier",
  "core.BasePreprocessor",
  "core.BaseTFApplier",
  "core.LabelingFunction",
  "core.Mapper",
  "core.Policy",
  "core.Preprocessor",
  "core.RowData",
  "core.apply_lfs_to_data_point",
  "core.labeling_function",
  "dask.dataframe",
  "dask.dataframe.from_pandas",
  "dask.distributed.Client",
  "datetime.datetime.now",
  "func",
  "functools.partial",
  "glob.glob",
  "hashlib.sha1",
  "input.new_full",
  "input.new_zeros",
  "input.shape",
  "inspect.getfullargspec",
  "itertools.chain",
  "itertools.chain.from_iterable",
  "itertools.product",
  "json.dump",
  "lf",
  "lf.LabelingFunction",
  "log_writer.LogWriter",
  "loggers.Checkpointer",
  "loggers.CheckpointerConfig",
  "loggers.LogManager",
  "loggers.LogManagerConfig",
  "loggers.LogWriter",
  "loggers.LogWriterConfig",
  "loggers.TensorBoardWriter",
  "logging.INFO",
  "logging.basicConfig",
  "logging.error",
  "logging.info",
  "logging.warning",
  "mapper",
  "mapper_no_pre",
  "mapper_pre",
  "mapper_pre.reset_cache",
  "mapper_pre_2",
  "mapper_spark",
  "metric",
  "modules.slice_combiner.SliceCombinerModule",
  "networkx.Graph",
  "networkx.chordal_graph_cliques",
  "networkx.is_chordal",
  "networkx.minimum_spanning_tree",
  "nlp",
  "nlp.BaseNLPLabelingFunction",
  "nlp.SpacyPreprocessorParameters",
  "nlp.base_nlp_labeling_function",
  "numpy.abs",
  "numpy.any",
  "numpy.array",
  "numpy.array_equal",
  "numpy.clip",
  "numpy.copy",
  "numpy.diag",
  "numpy.diagonal",
  "numpy.dtype",
  "numpy.empty",
  "numpy.errstate",
  "numpy.exp",
  "numpy.eye",
  "numpy.int",
  "numpy.int64",
  "numpy.lib.recfunctions.append_fields",
  "numpy.log",
  "numpy.max",
  "numpy.mod",
  "numpy.multiply",
  "numpy.nan_to_num",
  "numpy.ndarray",
  "numpy.not_equal",
  "numpy.ones",
  "numpy.ones_like",
  "numpy.random.choice",
  "numpy.random.rand",
  "numpy.random.randint",
  "numpy.random.random",
  "numpy.random.seed",
  "numpy.ravel",
  "numpy.recarray",
  "numpy.shape",
  "numpy.sqrt",
  "numpy.sum",
  "numpy.testing.assert_array_almost_equal",
  "numpy.testing.assert_array_equal",
  "numpy.testing.assert_equal",
  "numpy.tile",
  "numpy.vstack",
  "numpy.where",
  "numpy.zeros",
  "os.close",
  "os.makedirs",
  "os.path.dirname",
  "os.path.exists",
  "os.path.join",
  "os.remove",
  "pandas.DataFrame",
  "pandas.DataFrame.from_dict",
  "pandas.Index",
  "pandas.Series",
  "pandas.apply_lfs_to_data_point",
  "pandas.concat",
  "pandas.rows_to_triplets",
  "pandas.testing.assert_frame_equal",
  "pickle.dumps",
  "pickle.loads",
  "preprocessor",
  "pyspark.RDD",
  "pyspark.SparkContext",
  "pyspark.SparkContext.getOrCreate",
  "pyspark.sql.Row",
  "pyspark.sql.SQLContext",
  "pytest.mark.complex",
  "pytest.mark.spark",
  "random.randint",
  "random.seed",
  "random.shuffle",
  "scheduler.BatchIterator",
  "scheduler.Scheduler",
  "scheduler_class",
  "schedulers.batch_schedulers.get",
  "scipy.sparse.csr_matrix",
  "scipy.sparse.diags",
  "sequential_scheduler.SequentialScheduler",
  "shuffled_scheduler.ShuffledScheduler",
  "shutil.copyfile",
  "shutil.rmtree",
  "sklearn.metrics.accuracy_score",
  "sklearn.metrics.confusion_matrix",
  "sklearn.metrics.f1_score",
  "sklearn.metrics.fbeta_score",
  "sklearn.metrics.matthews_corrcoef",
  "sklearn.metrics.precision_score",
  "sklearn.metrics.recall_score",
  "sklearn.metrics.roc_auc_score",
  "snorkel.analysis.Scorer",
  "snorkel.analysis.metrics.METRICS",
  "snorkel.analysis.metrics.Metric",
  "snorkel.analysis.metrics._coverage_score",
  "snorkel.analysis.metrics._f1_macro_score",
  "snorkel.analysis.metrics._f1_micro_score",
  "snorkel.analysis.metrics._f1_score",
  "snorkel.analysis.metrics._roc_auc_score",
  "snorkel.analysis.metrics.metric_score",
  "snorkel.augmentation.ApplyAllPolicy",
  "snorkel.augmentation.ApplyEachPolicy",
  "snorkel.augmentation.ApplyOnePolicy",
  "snorkel.augmentation.MeanFieldPolicy",
  "snorkel.augmentation.PandasTFApplier",
  "snorkel.augmentation.RandomPolicy",
  "snorkel.augmentation.TFApplier",
  "snorkel.augmentation.apply.core.BaseTFApplier",
  "snorkel.augmentation.policy.core.ApplyAllPolicy",
  "snorkel.augmentation.policy.core.Policy",
  "snorkel.augmentation.policy.sampling.MeanFieldPolicy",
  "snorkel.augmentation.tf.BaseTransformationFunction",
  "snorkel.augmentation.transformation_function",
  "snorkel.classification.DictDataLoader",
  "snorkel.classification.DictDataset",
  "snorkel.classification.DictDataset.from_tensors",
  "snorkel.classification.MultitaskClassifier",
  "snorkel.classification.Operation",
  "snorkel.classification.Task",
  "snorkel.classification.Trainer",
  "snorkel.classification.cross_entropy_with_probs",
  "snorkel.classification.data.Batch",
  "snorkel.classification.data.DEFAULT_DATASET_NAME",
  "snorkel.classification.data.DEFAULT_INPUT_DATA_KEY",
  "snorkel.classification.data.DEFAULT_TASK_NAME",
  "snorkel.classification.data.DictDataLoader",
  "snorkel.classification.data.DictDataset",
  "snorkel.classification.data.XDict",
  "snorkel.classification.data.YDict",
  "snorkel.classification.data.collate_dicts",
  "snorkel.classification.multitask_classifier.ClassifierConfig",
  "snorkel.classification.multitask_classifier.MultitaskClassifier",
  "snorkel.classification.multitask_classifier.Operation",
  "snorkel.classification.multitask_classifier.OutputDict",
  "snorkel.classification.multitask_classifier.Task",
  "snorkel.classification.task.Operation",
  "snorkel.classification.training.loggers.checkpointer.CheckpointerConfig",
  "snorkel.classification.training.loggers.checkpointer.Metrics",
  "snorkel.classification.training.loggers.log_manager.LogManagerConfig",
  "snorkel.classification.training.loggers.log_writer.LogWriterConfig",
  "snorkel.classification.training.schedulers.scheduler.BatchIterator",
  "snorkel.classification.training.trainer.Metrics",
  "snorkel.classification.training.trainer.TrainerConfig",
  "snorkel.classification.training.trainer.logging",
  "snorkel.classification.utils.TensorCollection",
  "snorkel.classification.utils.collect_flow_outputs_by_suffix",
  "snorkel.classification.utils.list_to_tensor",
  "snorkel.classification.utils.metrics_dict_to_dataframe",
  "snorkel.classification.utils.move_to_device",
  "snorkel.classification.utils.pad_batch",
  "snorkel.labeling.LFAnalysis",
  "snorkel.labeling.LFApplier",
  "snorkel.labeling.LabelModel",
  "snorkel.labeling.LabelingFunction",
  "snorkel.labeling.MajorityClassVoter",
  "snorkel.labeling.MajorityLabelVoter",
  "snorkel.labeling.PandasLFApplier",
  "snorkel.labeling.RandomVoter",
  "snorkel.labeling.analysis.LFAnalysis",
  "snorkel.labeling.apply.core.BaseLFApplier",
  "snorkel.labeling.apply.core.RowData",
  "snorkel.labeling.apply.core.apply_lfs_to_data_point",
  "snorkel.labeling.apply.dask.DaskLFApplier",
  "snorkel.labeling.apply.dask.PandasParallelLFApplier",
  "snorkel.labeling.apply.dask.Scheduler",
  "snorkel.labeling.apply.pandas.PandasRowData",
  "snorkel.labeling.apply.pandas.apply_lfs_to_data_point",
  "snorkel.labeling.apply.pandas.rows_to_triplets",
  "snorkel.labeling.apply.spark.SparkLFApplier",
  "snorkel.labeling.filter_unlabeled_dataframe",
  "snorkel.labeling.labeling_function",
  "snorkel.labeling.lf.LabelingFunction",
  "snorkel.labeling.lf.core.LabelingFunction",
  "snorkel.labeling.lf.labeling_function",
  "snorkel.labeling.lf.nlp.BaseNLPLabelingFunction",
  "snorkel.labeling.lf.nlp.NLPLabelingFunction",
  "snorkel.labeling.lf.nlp.SpacyPreprocessorConfig",
  "snorkel.labeling.lf.nlp.SpacyPreprocessorParameters",
  "snorkel.labeling.lf.nlp.base_nlp_labeling_function",
  "snorkel.labeling.lf.nlp_spark.SparkNLPLabelingFunction",
  "snorkel.labeling.model.baselines.BaselineVoter",
  "snorkel.labeling.model.graph_utils.get_clique_tree",
  "snorkel.labeling.model.label_model.LabelModel",
  "snorkel.labeling.model.label_model.LabelModelConfig",
  "snorkel.labeling.model.label_model.Metrics",
  "snorkel.labeling.model.label_model.TrainConfig",
  "snorkel.labeling.model.label_model._CliqueData",
  "snorkel.labeling.model.logger.Logger",
  "snorkel.map.BaseMapper",
  "snorkel.map.LambdaMapper",
  "snorkel.map.Mapper",
  "snorkel.map.core.BaseMapper",
  "snorkel.map.core.LambdaMapper",
  "snorkel.map.core.MapFunction",
  "snorkel.map.core.get_hashable",
  "snorkel.map.core.get_parameters",
  "snorkel.map.core.is_hashable",
  "snorkel.map.lambda_mapper",
  "snorkel.map.spark._update_fields",
  "snorkel.map.spark.make_spark_mapper",
  "snorkel.preprocess.BasePreprocessor",
  "snorkel.preprocess.nlp.EN_CORE_WEB_SM",
  "snorkel.preprocess.nlp.SpacyPreprocessor",
  "snorkel.preprocess.preprocessor",
  "snorkel.preprocess.spark.make_spark_preprocessor",
  "snorkel.slicing.PandasSFApplier",
  "snorkel.slicing.SFApplier",
  "snorkel.slicing.SliceCombinerModule",
  "snorkel.slicing.SlicingClassifier",
  "snorkel.slicing.SlicingFunction",
  "snorkel.slicing.add_slice_labels",
  "snorkel.slicing.convert_to_slice_tasks",
  "snorkel.slicing.monitor.slice_dataframe",
  "snorkel.slicing.sf.SlicingFunction",
  "snorkel.slicing.sf.core.SlicingFunction",
  "snorkel.slicing.sf.nlp.NLPSlicingFunction",
  "snorkel.slicing.sf.nlp.nlp_slicing_function",
  "snorkel.slicing.slicing_function",
  "snorkel.synthetic.synthetic_data.generate_simple_label_matrix",
  "snorkel.types.Config",
  "snorkel.types.DataPoint",
  "snorkel.types.DataPoints",
  "snorkel.types.FieldMap",
  "snorkel.types.data.DataPoint",
  "snorkel.types.data.Field",
  "snorkel.utils.config_utils.merge_config",
  "snorkel.utils.core._get_mask",
  "snorkel.utils.core._hash",
  "snorkel.utils.data_operators.check_unique_names",
  "snorkel.utils.filter_labels",
  "snorkel.utils.lr_schedulers.ExponentialLRSchedulerConfig",
  "snorkel.utils.lr_schedulers.LRSchedulerConfig",
  "snorkel.utils.lr_schedulers.StepLRSchedulerConfig",
  "snorkel.utils.optimizers.AdamOptimizerConfig",
  "snorkel.utils.optimizers.AdamaxOptimizerConfig",
  "snorkel.utils.optimizers.OptimizerConfig",
  "snorkel.utils.optimizers.SGDOptimizerConfig",
  "snorkel.utils.preds_to_probs",
  "snorkel.utils.probs_to_preds",
  "snorkel.utils.set_seed",
  "snorkel.utils.to_int_label_array",
  "snorkel.version._MAJOR",
  "snorkel.version._MINOR",
  "snorkel.version._REVISION",
  "spacy.load",
  "split_words",
  "split_words_spark",
  "square_hit_tracker",
  "square_hit_tracker.n_hits",
  "task.Operation",
  "task.Task",
  "tempfile.mkdtemp",
  "tempfile.mkstemp",
  "tensorboardX.SummaryWriter",
  "test.augmentation.apply.test_tf_applier.DATA",
  "test.augmentation.apply.test_tf_applier.DATA_IN_PLACE_EXPECTED",
  "test.augmentation.apply.test_tf_applier.STR_DATA",
  "test.augmentation.apply.test_tf_applier.get_data_dict",
  "test.augmentation.apply.test_tf_applier.make_df",
  "test.augmentation.apply.test_tf_applier.modify_in_place",
  "test.augmentation.apply.test_tf_applier.square",
  "test.augmentation.apply.test_tf_applier.square_returns_none",
  "test.classification.test_multitask_classifier.BATCH_SIZE",
  "test.classification.test_multitask_classifier.NUM_EXAMPLES",
  "test.classification.test_multitask_classifier.create_dataloader",
  "test.classification.test_multitask_classifier.create_task",
  "test.classification.test_task.TASK_NAME",
  "test.labeling.apply.lf_applier_spark_test_script.DATA",
  "test.labeling.apply.lf_applier_spark_test_script.L_EXPECTED",
  "test.labeling.apply.lf_applier_spark_test_script.build_lf_matrix",
  "test.labeling.apply.lf_applier_spark_test_script.f",
  "test.labeling.apply.lf_applier_spark_test_script.g",
  "test.labeling.apply.test_lf_applier.DATA",
  "test.labeling.apply.test_lf_applier.L_EXPECTED",
  "test.labeling.apply.test_lf_applier.L_PREPROCESS_EXPECTED",
  "test.labeling.apply.test_lf_applier.L_TEXT_EXPECTED",
  "test.labeling.apply.test_lf_applier.SquareHitTracker",
  "test.labeling.apply.test_lf_applier.TEXT_DATA",
  "test.labeling.apply.test_lf_applier.f",
  "test.labeling.apply.test_lf_applier.f_np",
  "test.labeling.apply.test_lf_applier.fp",
  "test.labeling.apply.test_lf_applier.g",
  "test.labeling.apply.test_lf_applier.g_np",
  "test.labeling.apply.test_lf_applier.h",
  "test.labeling.apply.test_lf_applier.square",
  "test.labeling.apply.test_spark.DATA",
  "test.labeling.apply.test_spark.L_EXPECTED",
  "test.labeling.apply.test_spark.L_PREPROCESS_EXPECTED",
  "test.labeling.apply.test_spark.f",
  "test.labeling.apply.test_spark.fp",
  "test.labeling.apply.test_spark.g",
  "test.labeling.apply.test_spark.square",
  "test.labeling.test_analysis.L",
  "test.labeling.test_analysis.Y",
  "test.labeling.test_analysis.f",
  "test.labeling.test_convergence.copy_features",
  "test.labeling.test_convergence.create_data",
  "test.labeling.test_convergence.f",
  "test.labeling.test_convergence.get_negative_labeling_function",
  "test.labeling.test_convergence.get_positive_labeling_function",
  "test.map.test_core.MapperReturnsNone",
  "test.map.test_core.MapperWithArgs",
  "test.map.test_core.MapperWithKwargs",
  "test.map.test_core.MapperWithPre",
  "test.map.test_core.MapperWithPre2",
  "test.map.test_core.SplitWordsMapper",
  "test.map.test_core.SplitWordsMapperDefaultArgs",
  "test.map.test_core.SquareHitTracker",
  "test.map.test_core.modify_in_place",
  "test.map.test_core.square",
  "test.map.test_spark.MapperReturnsNone",
  "test.map.test_spark.SplitWordsMapper",
  "test.map.test_spark.SplitWordsMapperDefaultArgs",
  "test.map.test_spark.SquareHitTracker",
  "test.map.test_spark.modify_in_place",
  "test.map.test_spark.square",
  "test.slicing.apply.test_sf_applier.DATA",
  "test.slicing.apply.test_sf_applier.S_EXPECTED",
  "test.slicing.apply.test_sf_applier.S_PREPROCESS_EXPECTED",
  "test.slicing.apply.test_sf_applier.f",
  "test.slicing.apply.test_sf_applier.fp",
  "test.slicing.apply.test_sf_applier.g",
  "test.slicing.apply.test_sf_applier.square",
  "test.slicing.sf.test_nlp.combine_text",
  "test.slicing.sf.test_nlp.has_person_mention",
  "test.slicing.test_convergence.create_data",
  "test.slicing.test_convergence.create_dataloader",
  "test.slicing.test_convergence.create_task",
  "test.slicing.test_convergence.f",
  "test.slicing.test_convergence.g",
  "test.slicing.test_convergence.h",
  "test.slicing.test_monitor.DATA",
  "test.slicing.test_monitor.sf",
  "test.slicing.test_slicing_classifier.DATA",
  "test.slicing.test_slicing_classifier.create_dataset",
  "test.slicing.test_slicing_classifier.f",
  "test.slicing.test_slicing_classifier.g",
  "test.slicing.test_slicing_classifier.sfs",
  "test.slicing.test_utils.create_dummy_task",
  "test.slicing.test_utils.f",
  "test.utils.test_config_utils.BarConfig",
  "test.utils.test_config_utils.FooConfig",
  "test.utils.test_core.PREDS",
  "test.utils.test_core.PREDS_ROUND",
  "test.utils.test_core.PROBS",
  "tf",
  "torch.FloatTensor",
  "torch.LongTensor",
  "torch.Tensor",
  "torch.all",
  "torch.allclose",
  "torch.any",
  "torch.cat",
  "torch.clamp",
  "torch.cuda.is_available",
  "torch.device",
  "torch.diag",
  "torch.eq",
  "torch.equal",
  "torch.eye",
  "torch.float32",
  "torch.from_numpy",
  "torch.full_like",
  "torch.isclose",
  "torch.isnan",
  "torch.load",
  "torch.long",
  "torch.manual_seed",
  "torch.nn.DataParallel",
  "torch.nn.Identity",
  "torch.nn.Linear",
  "torch.nn.Module",
  "torch.nn.ModuleDict",
  "torch.nn.Parameter",
  "torch.nn.ReLU",
  "torch.nn.Sequential",
  "torch.nn.functional.cross_entropy",
  "torch.nn.functional.softmax",
  "torch.nn.utils.clip_grad_norm_",
  "torch.no_grad",
  "torch.norm",
  "torch.ones",
  "torch.optim.Adam",
  "torch.optim.Adamax",
  "torch.optim.Optimizer",
  "torch.optim.SGD",
  "torch.optim.lr_scheduler.ExponentialLR",
  "torch.optim.lr_scheduler.LambdaLR",
  "torch.optim.lr_scheduler.StepLR",
  "torch.optim.lr_scheduler._LRScheduler",
  "torch.rand_like",
  "torch.save",
  "torch.stack",
  "torch.sum",
  "torch.tensor",
  "torch.utils.data.DataLoader",
  "torch.utils.data.Dataset",
  "torch.zeros",
  "tqdm.tqdm",
  "tqdm.tqdm.pandas",
  "types.SimpleNamespace",
  "typing.Any",
  "typing.Callable",
  "typing.DefaultDict",
  "typing.Dict",
  "typing.Iterable",
  "typing.Iterator",
  "typing.List",
  "typing.Mapping",
  "typing.NamedTuple",
  "typing.Optional",
  "typing.Sequence",
  "typing.Set",
  "typing.Tuple",
  "typing.Union",
  "unittest.TestCase",
  "unittest.main",
  "utils.add_slice_labels",
  "utils.convert_to_slice_tasks",
  "utils.list_to_tensor"
 ],
 "deps": {
  "SimpleVoter": [],
  "abc": [],
  "call_fn": [],
  "checkpointer": [],
  "collections": [],
  "combiner_module": [],
  "core": [],
  "dask": [],
  "datetime": [],
  "func": [],
  "functools": [],
  "glob": [],
  "hashlib": [],
  "input": [],
  "inspect": [],
  "itertools": [],
  "json": [],
  "lf": [],
  "log_writer": [],
  "loggers": [],
  "logging": [],
  "mapper": [],
  "mapper_no_pre": [],
  "mapper_pre": [],
  "mapper_pre_2": [],
  "mapper_spark": [],
  "metric": [],
  "modules": [],
  "networkx": [],
  "nlp": [],
  "numpy": [],
  "os": [],
  "pandas": [],
  "pickle": [],
  "preprocessor": [],
  "pyspark": [],
  "pytest": [],
  "random": [],
  "scheduler": [],
  "scheduler_class": [],
  "schedulers": [],
  "scipy": [],
  "sequential_scheduler": [],
  "shuffled_scheduler": [],
  "shutil": [],
  "sklearn": [],
  "snorkel": [],
  "spacy": [],
  "split_words": [],
  "split_words_spark": [],
  "square_hit_tracker": [],
  "task": [],
  "tempfile": [],
  "tensorboardX": [],
  "test": [],
  "tf": [],
  "torch": [],
  "tqdm": [],
  "types": [],
  "typing": [],
  "unittest": [],
  "utils": []
 }
}